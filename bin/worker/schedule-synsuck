#!/usr/bin/perl
#
# schedule-synsuck-jobs
#
# This worker is used to schedule jobs for updating syndicated feeds.  This should
# be running all the time, or you can run it from cron with a --once option.
#
# Authors:
#      Mark Smith <mark@dreamwidth.org>
#
# Copyright (c) 2009 by Dreamwidth Studios, LLC.
#
# This program is free software; you may redistribute it and/or modify it under
# the same terms as Perl itself.  For a copy of the license, please reference
# 'perldoc perlartistic' or 'perldoc perlgpl'.
#

use lib "$ENV{LJHOME}/cgi-bin";
BEGIN {
    require 'ljlib.pl';
}

use Getopt::Long;

# verbose currently ignored; we're always chatty
my ( $once, $help, $verbose );
GetOptions(
    'once' => \$once,
    'help' => \$help,
    'verbose' => \$verbose,
) or usage();
usage() if $help;


# main loop; simply works until something terrible happens or we get killed
while ( 1 ) {
    print "[$$] Main loop beginning.\n";

    eval { work(); };
    warn $@ if $@;

    last if $once;
    sleep 60;
}


sub work {
    # clear caches, new dbs, etc
    LJ::start_request();
    my $dbh = LJ::get_db_writer()
        or die "unable to get db handle\n";
    my $sclient = LJ::theschwartz()
        or die "unable to get TheSchwartz client\n";

    # find feeds that are ready to be checked
    my $rows = $dbh->selectcol_arrayref(
        q{SELECT s.userid
          FROM user u, syndicated s
          WHERE u.userid = s.userid AND u.statusvis = 'V' AND s.checknext < NOW()
          LIMIT 500}
    ) || [];
    die $dbh->errstr if $dbh->err;

    # iterate and schedule jobs
    foreach my $row ( @$rows ) {
        my $rv = $sclient->insert( TheSchwartz::Job->new(
            funcname => 'DW::Worker::SynSuck',
            arg      => { userid => $row },

            # this ensures we don't have multiple TheSchwartz jobs for one particular feed
            uniqkey  => "synsuck:$row",
        ) );

        # advise only if we got the job scheduled
        print "[$$] Scheduling job for userid $row\n" if $rv;
    }
}


sub usage {
    die <<EOF;
$0 - schedules syndication jobs

    --once      Only run once; useful if you're using this worker in cron.
    --help      See this help/usage document.

In general, this worker should be scheduled by worker-manager (see etc/workers.conf)
and then it will just constantly ensure your syndicated accounts are being updated.

You will need to ensure you have scheduled synsuck workers.
EOF
}
